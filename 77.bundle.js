(window.webpackJsonp=window.webpackJsonp||[]).push([[77],{39:function(t,e,s){"use strict";s.d(e,"a",(function(){return MaxNorm})),s.d(e,"d",(function(){return UnitNorm})),s.d(e,"c",(function(){return NonNeg})),s.d(e,"b",(function(){return MinMaxNorm})),s.d(e,"f",(function(){return u})),s.d(e,"e",(function(){return h}));var n=s(0),o=s(50),i=s(12);
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
function a(t,e){return Object(n.Af)(()=>n.pf(n.tf(n.Ie(t,t),e,!0)))}class Constraint extends n.df.Serializable{getConfig(){return{}}}class MaxNorm extends Constraint{constructor(t){super(),this.defaultMaxValue=2,this.defaultAxis=0,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Object(n.Af)(()=>{const e=a(t,this.axis),s=n.Jd(e,0,this.maxValue);return n.Ie(t,n.Zd(s,n.td(Object(o.a)(),e)))})}getConfig(){return{maxValue:this.maxValue,axis:this.axis}}}MaxNorm.className="MaxNorm",n.df.registerClass(MaxNorm);class UnitNorm extends Constraint{constructor(t){super(),this.defaultAxis=0,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Object(n.Af)(()=>n.Zd(t,n.td(Object(o.a)(),a(t,this.axis))))}getConfig(){return{axis:this.axis}}}UnitNorm.className="UnitNorm",n.df.registerClass(UnitNorm);class NonNeg extends Constraint{apply(t){return n.Xe(t)}}NonNeg.className="NonNeg",n.df.registerClass(NonNeg);class MinMaxNorm extends Constraint{constructor(t){super(),this.defaultMinValue=0,this.defaultMaxValue=1,this.defaultRate=1,this.defaultAxis=0,this.minValue=null!=t.minValue?t.minValue:this.defaultMinValue,this.maxValue=null!=t.maxValue?t.maxValue:this.defaultMaxValue,this.rate=null!=t.rate?t.rate:this.defaultRate,this.axis=null!=t.axis?t.axis:this.defaultAxis}apply(t){return Object(n.Af)(()=>{const e=a(t,this.axis),s=n.td(n.Ie(this.rate,n.Jd(e,this.minValue,this.maxValue)),n.Ie(1-this.rate,e));return n.Ie(t,n.Zd(s,n.td(Object(o.a)(),e)))})}getConfig(){return{minValue:this.minValue,maxValue:this.maxValue,rate:this.rate,axis:this.axis}}}MinMaxNorm.className="MinMaxNorm",n.df.registerClass(MinMaxNorm);const r={maxNorm:"MaxNorm",minMaxNorm:"MinMaxNorm",nonNeg:"NonNeg",unitNorm:"UnitNorm"};function u(t){return Object(i.l)(t)}function l(t,e={}){return Object(i.g)(t,n.df.SerializationMap.getMap().classNameMap,e,"constraint")}function h(t){if(null==t)return null;if("string"==typeof t){return l({className:t in r?r[t]:t,config:{}})}return t instanceof Constraint?t:l(t)}},705:function(t,e,s){"use strict";s.d(e,"a",(function(){return Container}));var n=s(0),o=s(136),i=s(8),a=s(96),r=s(12),u=s(200),l=s(16),h=s(132),c=s(235),d=s(111),p=s(148),f=s(20);
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
class Container extends f.b{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=Object(o.b)(t)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],r.q(this.inputs).length!==this.inputs.length)throw new i.e("The list of inputs passed to the model is redundant. All inputs should only appear once. Found: "+this.inputs.map(t=>t.name));r.q(this.outputs).length!==this.outputs.length&&console.warn("The list of outputs passed to the model is redundant. All outputs should only appear once. Found: "+this.outputs.map(t=>t.name)),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const t of this.outputs){const e=t.sourceLayer,s=t.nodeIndex,n=t.tensorIndex;this.outputLayers.push(e),this.outputLayersNodeIndices.push(s),this.outputLayersTensorIndices.push(n)}for(const t of this.inputs){const e=t.sourceLayer,s=t.nodeIndex,n=t.tensorIndex;r.a(0===s,"input layer has >1 nodes"),r.a(0===n,"input layer has >1 tensors"),this.inputLayers.push(e),this.inputLayersNodeIndices.push(s),this.inputLayersTensorIndices.push(n)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let e=0;e<this.inputLayers.length;e++){const s=this.inputLayers[e];if(!(s instanceof p.b))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${e} (0-based) originates from layer type ${s.getClassName()}.`);this.inputNames.push(s.name),this.feedInputShapes.push(s.batchInputShape),this.feedInputNames.push(s.name)}for(const t of this.outputLayers)this.outputNames.push(t.name);this.internalInputShapes=this.inputs.map(t=>t.shape),this.internalOutputShapes=this.outputs.map(t=>t.shape);const e={},s={},n={},a={},u={},l=[],h=(t,e,s,n,o,a)=>{null!=n&&null!=o&&null!=a||(n=t.sourceLayer,o=t.nodeIndex,a=t.tensorIndex);const r=n.inboundNodes[o];if(-1!==s.indexOf(r))throw new i.d(`The tensor ${t.name} at layer "${n.name}" is part of a cycle.`);if(-1!==e.indexOf(r))return;this.containerNodes.add(Container.nodeKey(n,o)),n.id in u||(u[n.id]=Object.keys(u).length),-1===s.indexOf(r)&&s.push(r);const c=r.inboundLayers.length;for(let t=0;t<c;t++){const n=r.inputTensors[t],o=r.inboundLayers[t],i=r.nodeIndices[t],a=r.tensorIndices[t];h(n,e,s,o,i,a)}for(e.push(r);s.indexOf(r)>=0;)s.splice(s.indexOf(r),1);l.push(r)},c=[],d=[];for(const t of this.outputs)h(t,c,d);const m=l.slice().reverse();for(const t of m){s[t.id]=t,t.id in e||(e[t.id]=0);let o=e[t.id];const i=null==n[t.outboundLayer.id]?0:n[t.outboundLayer.id];o=Math.max(o,i),n[t.outboundLayer.id]=o,a[t.outboundLayer.id]=t.outboundLayer,e[t.id]=o;for(let n=0;n<t.inboundLayers.length;n++){const i=t.inboundLayers[n],a=t.nodeIndices[n],r=i.inboundNodes[a],u=null==e[r.id]?0:e[r.id];e[r.id]=Math.max(o+1,u),s[r.id]=r}}const y={};for(const t in e){const n=e[t];n in y||(y[n]=[]),y[n].push(s[t])}const g={};for(const t in n){const e=n[t];e in g||(g[e]=[]),g[e].push(a[t])}let b=Object.keys(g).map(t=>parseInt(t,10)).sort(r.k);this.layers=[];for(const t of b){const e=g[t];e.sort((t,e)=>{const s=u[t.id],n=u[e.id];return s<n?-1:s>n?1:0});for(const t of e)t instanceof Container&&this.internalContainerRefs.push(t),this.layers.push(t)}this.layersByDepth=g,b=Object.keys(y).map(t=>parseInt(t,10)).sort(r.k);const N=this.inputs.slice(),x=[];for(const t of b)for(const e of y[t]){const t=e.outboundLayer;if(null!=t){for(const s of e.inputTensors)if(-1===N.indexOf(s))throw new i.d("Graph disconnected: cannot obtain value for tensor "+s+` at layer "${t.name}". The following previous layers were accessed without issue: `+x);for(const t of e.outputTensors)N.push(t);x.push(t.name)}}this.nodesByDepth=y;const L=this.layers.map(t=>t.name);for(const t of L){const e=L.filter(e=>e===t).length;if(1!==e)throw new i.d(`The name "${t}" is used ${e} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(L))}this.outboundNodes=[],this.inboundNodes=[],new f.c({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map(t=>null),outputMasks:this.outputs.map(t=>null),inputShapes:this.inputs.map(t=>t.shape),outputShapes:this.outputs.map(t=>t.shape)}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach(e=>{e._trainableWeights.forEach(e=>e.trainable=t)}),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new i.e("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const s={};let n=0;for(const t of this.layers)for(const e of t.weights){if(null!=s[e.originalName])throw new i.e("Duplicate weight name: "+e.originalName);s[e.originalName]=e,n++}const o=[];for(const n in t){let a=n;if(null==s[n]){const t=n.split("/");a=t.slice(0,-2).concat([t[t.length-1]]).join("/")}if(null!=s[a])o.push([s[a],t[n]]);else if(e)throw new i.e("Provided weight data has no target variable: "+n);delete s[a]}if(e){const t=[];for(const e in s)t.push(e);if(t.length>0)throw new i.e(`${t.length} of ${n} weights are not set: `+t)}Object(h.c)(o)}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion="tfjs-layers "+c.a,e.backend="TensorFlow.js",e}toJSON(t,e=!0){const s=Object(u.b)(this.updatedConfig());return e?JSON.stringify(s):s}call(t,e){return Object(n.Af)(()=>{t=r.o(t);const s=new d.a;for(let e=0;e<this.inputs.length;++e)s.add(this.inputs[e],t[e]);return Object(d.b)(this.outputs,s,e)})}computeMask(t,e){return Object(n.Af)(()=>{let s;return t=r.o(t),s=null==e?r.j(null,t.length):r.o(e),this.runInternalGraph(t,s)[1]})}computeOutputShape(t){const e=l.d(t);if(e.length!==this.inputLayers.length)throw new i.e(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const s={};for(let t=0;t<e.length;t++){const n=this.inputLayers[t],o=e[t];s[n.name+"_0_0"]=o}const n=Object.keys(this.nodesByDepth).map(t=>parseInt(t,10)).sort(r.k);if(n.length>1)for(const t of n){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer;if(-1!==this.inputLayers.map(t=>t.id).indexOf(e.id))continue;const n=[];for(let e=0;e<t.inboundLayers.length;e++){const o=t.inboundLayers[e],i=t.nodeIndices[e],a=t.tensorIndices[e],r=s[`${o.name}_${i}_${a}`];n.push(r)}const o=e.computeOutputShape(r.m(n)),i=l.d(o),a=e.inboundNodes.indexOf(t);for(let t=0;t<i.length;t++){s[`${e.name}_${a}_${t}`]=i[t]}}}const o=[],a=[];for(let t=0;t<this.outputLayers.length;t++){const e=this.outputLayers[t],s=this.outputLayersNodeIndices[t],n=this.outputLayersTensorIndices[t],o=`${e.name}_${s}_${n}`;a.push(o)}for(let t=0;t<a.length;t++){const e=a[t];r.a(e in s),o.push(s[e])}return r.m(o)}runInternalGraph(t,e){null==e&&(e=r.j(null,t.length));const s={};for(let n=0;n<this.inputs.length;++n){const o=this.inputs[n],i=t[n],a=e[n];s[o.id]=[i,a]}const n=Object.keys(this.nodesByDepth).map(t=>parseInt(t,10)).sort(r.k);for(const t of n){const e=this.nodesByDepth[t];for(const t of e){const e=t.outboundLayer,n=t.inputTensors,o=t.outputTensors,a=new Array;for(const t of n)t.id in s&&a.push(s[t.id]);if(a.length===n.length){let n,u,l,h,c={};if(null!=t.callArgs&&(c=t.callArgs),1===a.length){const[t,s]=a[0];null==c.mask&&(c.mask=s),l=r.o(e.call(t,c)),h=r.o(e.computeMask(t,s)),n=[t],u=[s]}else n=a.map(t=>t[0]),u=a.map(t=>t[1]),null==c.mask&&(c.mask=u),l=r.o(e.call(n,c)),h=r.o(e.computeMask(n,u));if(e.activityRegularizer)throw new i.c("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let t=0;t<o.length;++t){const e=o[t],n=l[t],i=h[t];s[e.id]=[n,i]}}}}const o=[],a=[],u=[];for(const t of this.outputs){r.a(t.id in s,`Could not compute output ${t.name} : ${t.id}`);const[e,n]=s[t.id];u.push(e.shape),o.push(e),a.push(n)}return[o,a,u]}buildNodeConversionMap(t){const e={};let s;for(const t of this.layers){s=t instanceof Container?1:0;for(let n=0;n<t.inboundNodes.length;n++){const o=Container.nodeKey(t,n);this.containerNodes.has(o)&&(e[o]=s,s+=1)}}return e}getLayer(t,e){if(null!=e){if(this.layers.length<=e)throw new i.e(`Was asked to retrieve layer at index ${e}, but model only has ${this.layers.length} layer(s).`);return this.layers[e]}if(null==t)throw new i.e("Provide either a layer name or layer index");for(const e of this.layers)if(e.name===t)return e;throw new i.e("No such layer: "+t)}calculateLosses(){return Object(n.Af)(()=>{const t=[];for(const e of this.layers)for(let s=0;s<e.inboundNodes.length;++s){const n=Container.nodeKey(e,s);this.containerNodes.has(n)&&t.push(...e.calculateLosses())}return t})}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),s=[];for(const t of this.layers){const n=t.getClassName(),o=t.getConfig(),i=[];for(let s=0;s<t.inboundNodes.length;s++){const n=t.inboundNodes[s],o=Container.nodeKey(t,s);let a={};if(this.containerNodes.has(o)){if(n.callArgs)try{JSON.stringify(n.callArgs),a=n.callArgs}catch(e){console.warn(`Layer ${t.name} was passed non-serializable keyword arguments: `+n.callArgs+". They will not be included in the serialized model (and thus will be missing at deserialization time)."),a={}}if(n.inboundLayers.length>0){const t=[];for(let s=0;s<n.inboundLayers.length;s++){const o=n.inboundLayers[s],i=n.nodeIndices[s],r=n.tensorIndices[s];let u=e[Container.nodeKey(o,i)];null==u&&(u=0),t.push([o.name,u,r,a])}i.push(t)}}}const a={};a.name=t.name,a.className=n,a.config=o,a.inboundNodes=i,s.push(a)}t.layers=s;const n=[];for(let t=0;t<this.inputLayers.length;t++){const s=this.inputLayers[t],o=this.inputLayersNodeIndices[t],i=Container.nodeKey(s,o);if(!this.containerNodes.has(i))continue;let a=e[i];null==a&&(a=0);const r=this.inputLayersTensorIndices[t];n.push([s.name,a,r])}t.inputLayers=n;const o=[];for(let t=0;t<this.outputLayers.length;t++){const s=this.outputLayers[t],n=this.outputLayersNodeIndices[t],i=Container.nodeKey(s,n);if(!this.containerNodes.has(i))continue;let a=e[i];null==a&&(a=0);const r=this.outputLayersTensorIndices[t];o.push([s.name,a,r])}return t.outputLayers=o,t}static fromConfig(t,e,s={},n=!1){const o={},u={};function l(t,e){t.name in u?u[t.name].push(e):u[t.name]=[e]}function h(t,e){const s=[];let n;for(const i of e){const a=i[0],r=i[1],u=i[2];if(n=null==i[3]?{}:i[3],!(a in o))return void l(t,e);const h=o[a];if(h.inboundNodes.length<=r)return void l(t,e);const c=h.inboundNodes[r];s.push(c.outputTensors[u])}s.length>0&&t.apply(r.m(s),n)}function c(t){const s=t.name,r=Object(a.a)(t,null!=e.customObjects?e.customObjects:{});r.setFastWeightInitDuringBuild(n),o[s]=r;t.inboundNodes.forEach(t=>{if(!(t instanceof Array))throw new i.e("Corrupted configuration, expected array for nodeData: "+t);l(r,t)})}const d=e.name,p=e.layers;for(const t of p)c(t);for(;!r.h(u);)for(const t of p){const e=o[t.name];if(e.name in u){const t=u[e.name];delete u[e.name];for(const s of t)h(e,s)}}const f=[],m=[],y=e.inputLayers;for(const t of y){const e=t[0],s=t[1],n=t[2];r.a(e in o);const i=o[e].inboundNodes[s].outputTensors;f.push(i[n])}const g=e.outputLayers;for(const t of g){const e=t[0],s=t[1],n=t[2];r.a(e in o);const i=o[e].inboundNodes[s].outputTensors;m.push(i[n])}return new t({inputs:f,outputs:m,name:d})}get stateful(){if(this._stateful)throw new i.e("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){Object(n.Af)(()=>{this.layers.forEach(t=>{t.stateful&&t.resetStates()})})}}}}]);