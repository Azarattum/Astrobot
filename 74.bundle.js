(window.webpackJsonp=window.webpackJsonp||[]).push([[74],{206:function(t,e,n){"use strict";n.d(e,"b",(function(){return i})),n.d(e,"c",(function(){return r})),n.d(e,"a",(function(){return o}));var a=n(0);
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */function s(t,e,n){const a=e.length;if(null==t||Array.isArray(t)&&0===t.length)return e.map(t=>null);if(1===a)return Array.isArray(t)&&1===t.length?t:"object"==typeof t&&e[0]in t?[t[e[0]]]:[t];if(Array.isArray(t)){if(t.length!==a)throw new Error(`Provided ${n} is an array of ${t.length} element(s), but the model has ${a} outputs. Make sure a set of weights is provided for each model output.`);return t}if("object"==typeof t&&Object.keys(t).length>0&&"object"==typeof t[Object.keys(t)[0]]){const n=[];return e.forEach(e=>{e in t?n.push(t[e]):n.push(null)}),n}throw new Error(`The model has multiple (${a}) outputs, so ${n} must be either an array with ${a} elements or an object with ${e} keys. Provided ${n} not understood: ${JSON.stringify(t)}`)}function i(t,e){return s(t,e,"classWeight")}async function r(t,e,n,s){if(null!=e||null!=s)throw new Error("Support sampleWeight is not implemented yet");if(null!=n){const e=Object(a.Af)(()=>{if(1===t.shape.length)return Object(a.Kd)(t);if(2===t.shape.length){if(t.shape[1]>1){const e=1;return Object(a.wd)(t,e)}if(1===t.shape[1])return Object(a.Ye)(t,[t.shape[0]]);throw new Error(`Encountered unexpected last-dimension size (${t.shape[1]}) during handling of class weights. The size is expected to be >= 1.`)}throw new Error(`Unexpected rank of target (y) tensor (${t.rank}) during handling of class weights. The rank is expected to be 1 or 2.`)}),s=Array.from(await e.data());Object(a.Yd)(e);const i=[];return s.forEach(t=>{if(null==n[t])throw new Error(`classWeight must contain all classes in the training data. The class ${t} exists in the data but not in classWeight`);i.push(n[t])}),Object(a.xf)(i,"float32")}return null}function o(t,e){return Object(a.Ie)(t,e)}},450:function(t,e,n){"use strict";n.d(e,"b",(function(){return h})),n.d(e,"a",(function(){return d}));var a=n(0),s=n(108),i=n(8),r=n(110),o=n(12),c=n(206);function u(t,e){let n,s;const i=e;n=i.xs,s=i.ys,a.Hf.assert(null!=n&&null!=s,()=>"A Dataset iterator for fitDataset() is expected to generate objects of the form `{xs: xVal, ys: yVal}`, where the two values may be `tf.Tensor`, an array of Tensors, or a map of string to Tensor.  The provided Dataset instead generates "+e);const r=l("input",t.inputNames,n),o=l("output",t.outputNames,s),c=r[0].shape[0];a.Hf.assert(r.length===t.inputs.length,()=>`LayersModel has ${t.inputs.length} inputs, but the dataset provides ${r.length} inputs.  (Expected input keys: `+JSON.stringify(t.inputNames)+")"),a.Hf.assert(o.length===t.outputs.length,()=>`LayersModel has ${t.outputs.length} outputs, but the dataset provides ${o.length} outputs.  (Expected output keys: `+JSON.stringify(t.outputNames)+")");for(let e=0;e<r.length;e++)a.Hf.assert(r[e].shape[0]===c,()=>`Batch size mismatch: input ${t.inputNames[e]} has ${r[e].shape[0]}; expected  ${c} based on input ${t.inputNames[0]}.`);for(let e=0;e<o.length;e++)a.Hf.assert(o[e].shape[0]===c,()=>`Batch size mismatch: output ${t.outputNames[e]} has ${o[e].shape[0]}; expected  ${c} based on input ${t.inputNames[0]}.`);return{xs:r,ys:o}}function l(t,e,n){if(n instanceof a.hd)return[n];if(Array.isArray(n))return a.Hf.assert(n.length===e.length,()=>`Received an array of ${n.length} Tensors, but expected ${e.length} to match the ${t} keys ${e}.`),n;{const a=[];for(const s of e){if(null==n[s])throw new i.e(`The feature data generated by the dataset lacks the required ${t} key '${s}'.`);a.push(n[s])}return a}}async function h(t,e,n){const l=null!=n.batchesPerEpoch;if(a.Hf.assert(null!=t.optimizer,()=>"You must compile a model before training/testing. Use LayersModel.compile(modelCompileConfig)."),a.Hf.assert(null!=n,()=>"For fitDataset(), the 2nd argument (config) is required, but it is not provided in this call."),a.Hf.assert(null!=n.epochs&&n.epochs>0&&Number.isInteger(n.epochs),()=>"For fitDataset(), config.epochs is expected to be a positive integer, but got "+n.epochs),a.Hf.assert(!l||n.batchesPerEpoch>0&&Number.isInteger(n.batchesPerEpoch),()=>"For fitDataset(), config.batchesPerEpoch is expected to be a positive integer if specified, but got "+n.batchesPerEpoch),a.Hf.assert(null==n.validationSplit,()=>"`validationSplit` is not supported by `fitDataset()`. Use validationData instead."),t.isTraining)throw new Error("Cannot start training because another fit() call is ongoing.");t.isTraining=!0;try{const h=null!=n.validationData;let d,p;if(h)if(f(n.validationData))a.Hf.assert(null==n.validationBatches||n.validationBatches>0&&Number.isInteger(n.validationBatches),()=>"For fitDataset() with dataset-based validation, config.validationBatches is expected not to be provided, or to be a positive integer, but got "+n.validationBatches);else{const t=function(t){if(3===t.length)throw new i.c("Validation with sample weights is not implemented yet.");return{xs:t[0],ys:t[1]}}(n.validationData);d=t.xs,p=t.ys}const b=t.makeTrainFunction(),g=t.getDedupedMetricsNames();let y;y=h?g.slice().concat(g.map(t=>"val_"+t)):g.slice();const m=Object(s.d)(n.callbacks,n.yieldEvery),w=null==n.verbose?1:n.verbose,{callbackList:v,history:E}=Object(s.c)(m,w,n.epochs,null,null,function(t,e){let n=null;null!=e.batchesPerEpoch?n=e.batchesPerEpoch:Number.isFinite(t.size)&&(n=t.size);return n}(e,n),null,h,y);v.setModel(t),t.history=E,await v.onTrainBegin(),t.stopTraining_=!1;let x=null==n.initialEpoch?0:n.initialEpoch,$=await e.iterator();for(;x<n.epochs;){const s={};await v.onEpochBegin(x);let i=0,y=0;for(l||($=await e.iterator());!l||i<n.batchesPerEpoch;){const e=await $.next();if(l&&e.done){console.warn("You provided `batchesPerEpoch` as "+n.batchesPerEpoch+", but your dataset iterator ran out of data after "+i+" batches; interrupting training. Make sure that your dataset can generate at least `batchesPerEpoch * epochs` batches (in this case, "+n.batchesPerEpoch*n.epochs+" batches). You may need to use the repeat() function when building your dataset.");break}if(null!=e.value){const{xs:s,ys:o}=u(t,e.value),l={};l.batch=y,l.size=s[0].shape[0],await v.onBatchBegin(y,l);const h=[];if(null!=n.classWeight){const e=Object(c.b)(n.classWeight,t.outputNames);for(let t=0;t<e.length;++t)h.push(await Object(c.c)(o[t],null,e[t]))}const f=s.concat(o).concat(h),d=b(f);a.Yd(f);for(let t=0;t<g.length;++t){const e=g[t],n=d[t];l[e]=n,a.qe(n)}await v.onBatchEnd(y,l),Object(r.a)(l),y++,i++}if(l?i>=n.batchesPerEpoch:e.done){if(h){let e;e=f(n.validationData)?Object(o.o)(await t.evaluateDataset(n.validationData,{batches:n.validationBatches})):Object(o.o)(t.evaluate(d,p,{batchSize:null==n.validationBatchSize?32:n.validationBatchSize,verbose:0}));for(let n=0;n<t.metricsNames.length;++n)s["val_"+t.metricsNames[n]]=e[n]}break}if(t.stopTraining_)break}if(await v.onEpochEnd(x,s),x++,t.stopTraining_)break}return await v.onTrainEnd(),await t.history.syncData(),t.history}finally{t.isTraining=!1}}function f(t){return"function"==typeof t.iterator}async function d(t,e,n){const s=null!=(n=n||{}).batches,r=t.testFunction;let c=[];if(n.verbose>0)throw new i.c("Verbose mode is not implemented yet.");a.Hf.assert(!s||n.batches>0&&Number.isInteger(n.batches),()=>"Test loop expects `batches` to be a positive integer, but received "+JSON.stringify(n.batches));const l="function"==typeof e.next?e:await e.iterator();let h=0,f=0;for(;!s||f<n.batches;){const e=await l.next();if(c=a.Af(()=>{if(e.value){const{xs:n,ys:s}=u(t,e.value),i=n.concat(s),o=a.Af(()=>r(i));if(a.Yd(i),0===f)for(let t=0;t<o.length;++t)c.push(Object(a.af)(0));const l=i[0].shape[0];for(let t=0;t<o.length;++t){const e=o[t],n=c[t];c[t]=a.Af(()=>a.td(c[t],a.Ie(l,e))),f>0&&a.Yd(n)}a.Yd(o),h+=l,++f}return c}),e.done){s&&console.warn(`Your dataset iterator ran out of data during evaluateDataset(). Interrupting evalution. Make sure that your dataset can generate at least \`batches\` batches (in this case, ${n.batches} batches). You may need to use the repeat() function when building your dataset.`);break}}for(let t=0;t<c.length;++t){const e=c[t];c[t]=a.Zd(c[t],h),a.Yd(e)}return Object(o.m)(c)}},63:function(t,e,n){"use strict";n.d(e,"a",(function(){return i})),n.d(e,"e",(function(){return r})),n.d(e,"f",(function(){return o})),n.d(e,"d",(function(){return c})),n.d(e,"c",(function(){return u})),n.d(e,"b",(function(){return l}));var a=n(0),s=n(21);
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
function i(t){a.Hf.assert(t>0&&Number.isInteger(t),()=>"batchSize is required to be a positive integer, but got "+t)}function r(t,e,n){return null==t?[null]:Array.isArray(t)?t.map(t=>Object(s.q)(t,e,n-e)):Object(s.q)(t,e,n-e)}function o(t,e){return a.Af(()=>null==t?null:Array.isArray(t)?t.map(t=>o(t,e)):Object(s.k)(t,"int32"===e.dtype?e:a.Id(e,"int32")))}function c(t,e){const n=[];let a=0,s=null;for(;a<t;)s=a+e,s>=t&&(s=t),n.push([a,s]),a=s;return n}function u(t){const e=[];t instanceof a.hd&&(t=[t]);for(let n=0;n<t.length;++n){const a=t[n];if(1===a.rank)e.push(Object(s.i)(a,1));else{if(0===a.rank)throw new Error("Expected tensor to be at least 1D, but received a 0D tensor (scalar).");e.push(a)}}return e}function l(t,e){if(null==t)return;const n=[];if(e instanceof a.hd)n.push(e.id);else if(Array.isArray(e))e.forEach(t=>n.push(t.id));else if(null!=e)for(const t in e){const a=e[t];n.push(a.id)}const s=[];if(t instanceof a.hd)-1===n.indexOf(t.id)&&s.push(t);else if(Array.isArray(t))t.forEach(t=>{-1===n.indexOf(t.id)&&s.push(t)});else if(null!=t)for(const e in t){const a=t[e];-1===n.indexOf(a.id)&&s.push(a)}s.forEach(t=>{t.isDisposed||t.dispose()})}}}]);