(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{104:function(e,t,i){"use strict";i.d(t,"j",(function(){return f})),i.d(t,"k",(function(){return m})),i.d(t,"a",(function(){return BaseConv})),i.d(t,"c",(function(){return Conv2D})),i.d(t,"e",(function(){return Conv3D})),i.d(t,"d",(function(){return Conv2DTranspose})),i.d(t,"f",(function(){return Conv3DTranspose})),i.d(t,"h",(function(){return SeparableConv2D})),i.d(t,"b",(function(){return Conv1D})),i.d(t,"g",(function(){return Cropping2D})),i.d(t,"i",(function(){return UpSampling2D}));var s=i(0),n=i(74),a=i(50),r=i(21),l=i(31),o=i(39),h=i(20),c=i(8),u=i(26),d=i(30),p=i(54),b=i(12),g=i(16);
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
function f(e,t){return Object(s.Af)(()=>(Object(l.a)(t),"channelsFirst"===t?s.Df(e,[0,2,3,1]):e))}function m(e,t){return Object(s.Af)(()=>(Object(l.a)(t),"channelsFirst"===t?s.Df(e,[0,2,3,4,1]):e))}function C(e,t,i,n=1,o="valid",h,u=1){return Object(s.Af)(()=>{if(null==h&&(h=Object(a.b)()),Object(l.a)(h),3!==e.shape.length)throw new c.e("The input of a conv1dWithBias operation should be 3, but is "+e.shape.length+" instead.");if(3!==t.shape.length)throw new c.e("The kernel for a conv1dWithBias operation should be 3, but is "+t.shape.length+" instead");if(null!=i&&1!==i.shape.length)throw new c.e("The bias for a conv1dWithBias operation should be 1, but is "+t.shape.length+" instead");if("channelsFirst"===h&&(e=s.Df(e,[0,2,1])),"causal"===o)throw new c.c("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");let d=s.Qd(e,t,n,"same"===o?"same":"valid","NWC",u);return null!=i&&(d=r.b(d,i)),d})}function v(e,t,i,n=[1,1],r="valid",o,h,u=null){return Object(s.Af)(()=>{if(null==o&&(o=Object(a.b)()),Object(l.a)(o),3!==e.rank&&4!==e.rank)throw new c.e(`conv2dWithBiasActivation expects input to be of rank 3 or 4, but received ${e.rank}.`);if(3!==t.rank&&4!==t.rank)throw new c.e(`conv2dWithBiasActivation expects kernel to be of rank 3 or 4, but received ${e.rank}.`);let d=f(e,o);if("causal"===r)throw new c.c("The support for CAUSAL padding mode in conv1dWithBias is not implemented yet.");return d=s.ke.conv2d({x:d,filter:t,strides:n,pad:"same"===r?"same":"valid",dilations:h,dataFormat:"NHWC",bias:i,activation:u}),"channelsFirst"===o&&(d=s.Df(d,[0,3,1,2])),d})}function k(e,t,i,n=[1,1,1],o="valid",h,u){return Object(s.Af)(()=>{if(null==h&&(h=Object(a.b)()),Object(l.a)(h),4!==e.rank&&5!==e.rank)throw new c.e("conv3dWithBias expects input to be of rank 4 or 5, but received "+e.rank+".");if(4!==t.rank&&5!==t.rank)throw new c.e("conv3dWithBias expects kernel to be of rank 4 or 5, but received "+e.rank+".");let d=m(e,h);if("causal"===o)throw new c.c("The support for CAUSAL padding mode in conv3dWithBias is not implemented yet.");return d=s.Td(d,t,n,"same"===o?"same":"valid","NDHWC",u),null!=i&&(d=r.b(d,i)),"channelsFirst"===h&&(d=s.Df(d,[0,4,1,2,3])),d})}class BaseConv extends h.b{constructor(e,t){if(super(t),this.bias=null,this.DEFAULT_KERNEL_INITIALIZER="glorotNormal",this.DEFAULT_BIAS_INITIALIZER="zeros",BaseConv.verifyArgs(t),this.rank=e,b.b(this.rank,"rank"),1!==this.rank&&2!==this.rank&&3!==this.rank)throw new c.c(`Convolution layer for rank other than 1, 2, or 3 (${this.rank}) is not implemented yet.`);if(this.kernelSize=Object(p.c)(t.kernelSize,e,"kernelSize"),this.strides=Object(p.c)(null==t.strides?1:t.strides,e,"strides"),this.padding=null==t.padding?"valid":t.padding,Object(l.c)(this.padding),this.dataFormat=null==t.dataFormat?"channelsLast":t.dataFormat,Object(l.a)(this.dataFormat),this.activation=Object(n.b)(t.activation),this.useBias=null==t.useBias||t.useBias,this.biasInitializer=Object(u.q)(t.biasInitializer||this.DEFAULT_BIAS_INITIALIZER),this.biasConstraint=Object(o.e)(t.biasConstraint),this.biasRegularizer=Object(d.b)(t.biasRegularizer),this.activityRegularizer=Object(d.b)(t.activityRegularizer),this.dilationRate=Object(p.c)(null==t.dilationRate?1:t.dilationRate,e,"dilationRate"),1===this.rank&&Array.isArray(this.dilationRate)&&1!==this.dilationRate.length)throw new c.e("dilationRate must be a number or an array of a single number for 1D convolution, but received "+JSON.stringify(this.dilationRate));if(2===this.rank){if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate];else if(2!==this.dilationRate.length)throw new c.e("dilationRate must be a number or array of two numbers for 2D convolution, but received "+JSON.stringify(this.dilationRate))}else if(3===this.rank)if("number"==typeof this.dilationRate)this.dilationRate=[this.dilationRate,this.dilationRate,this.dilationRate];else if(3!==this.dilationRate.length)throw new c.e("dilationRate must be a number or array of three numbers for 3D convolution, but received "+JSON.stringify(this.dilationRate))}static verifyArgs(e){if(b.a("kernelSize"in e,"required key 'kernelSize' not in config"),"number"!=typeof e.kernelSize&&!b.c(e.kernelSize,"number",1,3))throw new c.e(`BaseConv expects config.kernelSize to be number or number[] with length 1, 2, or 3, but received ${JSON.stringify(e.kernelSize)}.`)}getConfig(){const e={kernelSize:this.kernelSize,strides:this.strides,padding:this.padding,dataFormat:this.dataFormat,dilationRate:this.dilationRate,activation:Object(n.c)(this.activation),useBias:this.useBias,biasInitializer:Object(u.r)(this.biasInitializer),biasRegularizer:Object(d.e)(this.biasRegularizer),activityRegularizer:Object(d.e)(this.activityRegularizer),biasConstraint:Object(o.f)(this.biasConstraint)},t=super.getConfig();return Object.assign(e,t),e}}class Conv extends BaseConv{constructor(e,t){super(e,t),this.kernel=null,Conv.verifyArgs(t),this.filters=t.filters,b.b(this.filters,"filters"),this.kernelInitializer=Object(u.q)(t.kernelInitializer||this.DEFAULT_KERNEL_INITIALIZER),this.kernelConstraint=Object(o.e)(t.kernelConstraint),this.kernelRegularizer=Object(d.b)(t.kernelRegularizer)}build(e){e=Object(g.a)(e);const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new c.e("The channel dimension of the input should be defined. Found "+e[t]);const i=e[t],s=this.kernelSize.concat([i,this.filters]);this.kernel=this.addWeight("kernel",s,null,this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],null,this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[{ndim:this.rank+2,axes:{[t]:i}}],this.built=!0}call(e,t){return Object(s.Af)(()=>{let t;e=Object(g.b)(e);const i=null==this.bias?null:this.bias.read(),s=b.i(this.activation.getClassName());if(null!=s&&2===this.rank)t=v(e,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate,s);else{if(1===this.rank)t=C(e,this.kernel.read(),i,this.strides[0],this.padding,this.dataFormat,this.dilationRate[0]);else if(2===this.rank)t=v(e,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate);else{if(3!==this.rank)throw new c.c("convolutions greater than 3D are not implemented yet.");t=k(e,this.kernel.read(),i,this.strides,this.padding,this.dataFormat,this.dilationRate)}null!=this.activation&&(t=this.activation.apply(t))}return t})}computeOutputShape(e){e=Object(g.a)(e);const t=[],i="channelsLast"===this.dataFormat?e.slice(1,e.length-1):e.slice(2);for(let e=0;e<i.length;++e){const s=Object(p.a)(i[e],this.kernelSize[e],this.padding,this.strides[e],"number"==typeof this.dilationRate?this.dilationRate:this.dilationRate[e]);t.push(s)}let s=[e[0]];return"channelsLast"===this.dataFormat?(s=s.concat(t),s.push(this.filters)):(s.push(this.filters),s=s.concat(t)),s}getConfig(){const e={filters:this.filters,kernelInitializer:Object(u.r)(this.kernelInitializer),kernelRegularizer:Object(d.e)(this.kernelRegularizer),kernelConstraint:Object(o.f)(this.kernelConstraint)},t=super.getConfig();return Object.assign(e,t),e}static verifyArgs(e){if(!("filters"in e)||"number"!=typeof e.filters||e.filters<1)throw new c.e("Convolution layer expected config.filters to be a 'number' > 0 but got "+JSON.stringify(e.filters))}}class Conv2D extends Conv{constructor(e){super(2,e),Conv2D.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!b.c(e.kernelSize,"number",1,2))throw new c.e(`Conv2D expects config.kernelSize to be number or number[] with length 1 or 2, but received ${JSON.stringify(e.kernelSize)}.`)}}Conv2D.className="Conv2D",s.df.registerClass(Conv2D);class Conv3D extends Conv{constructor(e){super(3,e),Conv3D.verifyArgs(e)}getConfig(){const e=super.getConfig();return delete e.rank,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&(!Array.isArray(e.kernelSize)||1!==e.kernelSize.length&&3!==e.kernelSize.length))throw new c.e(`Conv3D expects config.kernelSize to be number or [number, number, number], but received ${JSON.stringify(e.kernelSize)}.`)}}Conv3D.className="Conv3D",s.df.registerClass(Conv3D);class Conv2DTranspose extends Conv2D{constructor(e){if(super(e),this.inputSpec=[new h.a({ndim:4})],"same"!==this.padding&&"valid"!==this.padding)throw new c.e("Conv2DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode "+this.padding)}build(e){if(4!==(e=Object(g.a)(e)).length)throw new c.e("Input should have rank 4; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new c.e("The channel dimension of the inputs should be defined. Found `None`.");const i=e[t],s=this.kernelSize.concat([this.filters,i]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new h.a({ndim:4,axes:{[t]:i}})],this.built=!0}call(e,t){return s.Af(()=>{let t=Object(g.b)(e);if(4!==t.shape.length)throw new c.e("Conv2DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-"+t.shape.length);const i=t.shape,n=i[0];let a,l;"channelsFirst"===this.dataFormat?(a=2,l=3):(a=1,l=2);const o=i[a],h=i[l],u=this.kernelSize[0],d=this.kernelSize[1],b=this.strides[0],f=this.strides[1],m=[n,Object(p.b)(o,b,u,this.padding),Object(p.b)(h,f,d,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=s.Df(t,[0,2,3,1]));let C=s.Sd(t,this.kernel.read(),m,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(C=s.Df(C,[0,3,1,2])),null!=this.bias&&(C=r.b(C,this.bias.read(),this.dataFormat)),null!=this.activation&&(C=this.activation.apply(C)),C})}computeOutputShape(e){const t=(e=Object(g.a)(e)).slice();let i,s,n;"channelsFirst"===this.dataFormat?(i=1,s=2,n=3):(i=3,s=1,n=2);const a=this.kernelSize[0],r=this.kernelSize[1],l=this.strides[0],o=this.strides[1];return t[i]=this.filters,t[s]=Object(p.b)(t[s],l,a,this.padding),t[n]=Object(p.b)(t[n],o,r,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}Conv2DTranspose.className="Conv2DTranspose",s.df.registerClass(Conv2DTranspose);class Conv3DTranspose extends Conv3D{constructor(e){if(super(e),this.inputSpec=[new h.a({ndim:5})],"same"!==this.padding&&"valid"!==this.padding)throw new c.e("Conv3DTranspose currently supports only padding modes 'same' and 'valid', but received padding mode "+this.padding)}build(e){if(5!==(e=Object(g.a)(e)).length)throw new c.e("Input should have rank 5; Received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t])throw new c.e("The channel dimension of the inputs should be defined. Found `None`.");const i=e[t],s=this.kernelSize.concat([this.filters,i]);this.kernel=this.addWeight("kernel",s,"float32",this.kernelInitializer,this.kernelRegularizer,!0,this.kernelConstraint),this.useBias&&(this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint)),this.inputSpec=[new h.a({ndim:5,axes:{[t]:i}})],this.built=!0}call(e,t){return s.Af(()=>{let t=Object(g.b)(e);if(5!==t.shape.length)throw new c.e("Conv3DTranspose.call() expects input tensor to be rank-4, but received a tensor of rank-"+t.shape.length);const i=t.shape,n=i[0];let a,l,o;"channelsFirst"===this.dataFormat?(o=2,a=3,l=4):(o=1,a=2,l=3);const h=i[o],u=i[a],d=i[l],b=this.kernelSize[0],f=this.kernelSize[1],m=this.kernelSize[2],C=this.strides[0],v=this.strides[1],k=this.strides[2],w=[n,Object(p.b)(h,C,b,this.padding),Object(p.b)(u,v,f,this.padding),Object(p.b)(d,k,m,this.padding),this.filters];"channelsLast"!==this.dataFormat&&(t=s.Df(t,[0,2,3,4,1]));let z=s.Ud(t,this.kernel.read(),w,this.strides,this.padding);return"channelsLast"!==this.dataFormat&&(z=s.Df(z,[0,4,1,2,3])),null!==this.bias&&(z=r.b(z,this.bias.read(),this.dataFormat)),null!==this.activation&&(z=this.activation.apply(z)),z})}computeOutputShape(e){const t=(e=Object(g.a)(e)).slice();let i,s,n,a;"channelsFirst"===this.dataFormat?(i=1,s=2,n=3,a=4):(i=4,s=1,n=2,a=3);const r=this.kernelSize[0],l=this.kernelSize[1],o=this.kernelSize[2],h=this.strides[0],c=this.strides[1],u=this.strides[2];return t[i]=this.filters,t[s]=Object(p.b)(t[s],h,r,this.padding),t[n]=Object(p.b)(t[n],c,l,this.padding),t[a]=Object(p.b)(t[a],u,o,this.padding),t}getConfig(){const e=super.getConfig();return delete e.dilationRate,e}}Conv3DTranspose.className="Conv3DTranspose",s.df.registerClass(Conv3DTranspose);class SeparableConv extends Conv{constructor(e,t){if(super(e,t),this.DEFAULT_DEPTHWISE_INITIALIZER="glorotUniform",this.DEFAULT_POINTWISE_INITIALIZER="glorotUniform",this.depthwiseKernel=null,this.pointwiseKernel=null,null==t.filters)throw new c.e("The `filters` configuration field is required by SeparableConv, but is unspecified.");if(null!=t.kernelInitializer||null!=t.kernelRegularizer||null!=t.kernelConstraint)throw new c.e("Fields kernelInitializer, kernelRegularizer and kernelConstraint are invalid for SeparableConv2D. Use depthwiseInitializer, depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, pointwiseRegularizer and pointwiseConstraint instead.");if(null!=t.padding&&"same"!==t.padding&&"valid"!==t.padding)throw new c.e(`SeparableConv${this.rank}D supports only padding modes: 'same' and 'valid', but received `+JSON.stringify(t.padding));this.depthMultiplier=null==t.depthMultiplier?1:t.depthMultiplier,this.depthwiseInitializer=Object(u.q)(t.depthwiseInitializer||this.DEFAULT_DEPTHWISE_INITIALIZER),this.depthwiseRegularizer=Object(d.b)(t.depthwiseRegularizer),this.depthwiseConstraint=Object(o.e)(t.depthwiseConstraint),this.pointwiseInitializer=Object(u.q)(t.depthwiseInitializer||this.DEFAULT_POINTWISE_INITIALIZER),this.pointwiseRegularizer=Object(d.b)(t.pointwiseRegularizer),this.pointwiseConstraint=Object(o.e)(t.pointwiseConstraint)}build(e){if((e=Object(g.a)(e)).length<this.rank+2)throw new c.e(`Inputs to SeparableConv${this.rank}D should have rank `+(this.rank+2)+", but received input shape: "+JSON.stringify(e));const t="channelsFirst"===this.dataFormat?1:e.length-1;if(null==e[t]||e[t]<0)throw new c.e("The channel dimension of the inputs should be defined, but found "+JSON.stringify(e[t]));const i=e[t],s=this.kernelSize.concat([i,this.depthMultiplier]),n=[];for(let e=0;e<this.rank;++e)n.push(1);n.push(i*this.depthMultiplier,this.filters);this.depthwiseKernel=this.addWeight("depthwise_kernel",s,"float32",this.depthwiseInitializer,this.depthwiseRegularizer,!0,this.depthwiseConstraint),this.pointwiseKernel=this.addWeight("pointwise_kernel",n,"float32",this.pointwiseInitializer,this.pointwiseRegularizer,!0,this.pointwiseConstraint),this.useBias?this.bias=this.addWeight("bias",[this.filters],"float32",this.biasInitializer,this.biasRegularizer,!0,this.biasConstraint):this.bias=null,this.inputSpec=[new h.a({ndim:this.rank+2,axes:{[t]:i}})],this.built=!0}call(e,t){return Object(s.Af)(()=>{let t;if(e=Object(g.b)(e),1===this.rank)throw new c.c("1D separable convolution is not implemented yet.");return 2===this.rank&&("channelsFirst"===this.dataFormat&&(e=s.Df(e,[0,2,3,1])),t=s.cf(e,this.depthwiseKernel.read(),this.pointwiseKernel.read(),this.strides,this.padding,this.dilationRate,"NHWC")),this.useBias&&(t=r.b(t,this.bias.read(),this.dataFormat)),null!=this.activation&&(t=this.activation.apply(t)),"channelsFirst"===this.dataFormat&&(t=s.Df(t,[0,3,1,2])),t})}getConfig(){const e=super.getConfig();return delete e.rank,delete e.kernelInitializer,delete e.kernelRegularizer,delete e.kernelConstraint,e.depthwiseInitializer=Object(u.r)(this.depthwiseInitializer),e.pointwiseInitializer=Object(u.r)(this.pointwiseInitializer),e.depthwiseRegularizer=Object(d.e)(this.depthwiseRegularizer),e.pointwiseRegularizer=Object(d.e)(this.pointwiseRegularizer),e.depthwiseConstraint=Object(o.f)(this.depthwiseConstraint),e.pointwiseConstraint=Object(o.f)(this.pointwiseConstraint),e}}SeparableConv.className="SeparableConv";class SeparableConv2D extends SeparableConv{constructor(e){super(2,e)}}SeparableConv2D.className="SeparableConv2D",s.df.registerClass(SeparableConv2D);class Conv1D extends Conv{constructor(e){super(1,e),Conv1D.verifyArgs(e),this.inputSpec=[{ndim:3}]}getConfig(){const e=super.getConfig();return delete e.rank,delete e.dataFormat,e}static verifyArgs(e){if("number"!=typeof e.kernelSize&&!b.c(e.kernelSize,"number",1,1))throw new c.e(`Conv1D expects config.kernelSize to be number or number[] with length 1, but received ${JSON.stringify(e.kernelSize)}.`)}}Conv1D.className="Conv1D",s.df.registerClass(Conv1D);class Cropping2D extends h.b{constructor(e){super(e),"number"==typeof e.cropping?this.cropping=[[e.cropping,e.cropping],[e.cropping,e.cropping]]:"number"==typeof e.cropping[0]?this.cropping=[[e.cropping[0],e.cropping[0]],[e.cropping[1],e.cropping[1]]]:this.cropping=e.cropping,this.dataFormat=void 0===e.dataFormat?"channelsLast":e.dataFormat,this.inputSpec=[{ndim:4}]}computeOutputShape(e){return"channelsFirst"===this.dataFormat?[e[0],e[1],e[2]-this.cropping[0][0]-this.cropping[0][1],e[3]-this.cropping[1][0]-this.cropping[1][1]]:[e[0],e[1]-this.cropping[0][0]-this.cropping[0][1],e[2]-this.cropping[1][0]-this.cropping[1][1],e[3]]}call(e,t){return Object(s.Af)(()=>{if(e=Object(g.b)(e),"channelsLast"===this.dataFormat){const t=r.p(e,this.cropping[0][0],e.shape[1]-this.cropping[0][0]-this.cropping[0][1],2);return r.p(t,this.cropping[1][0],e.shape[2]-this.cropping[1][1]-this.cropping[1][0],3)}{const t=r.p(e,this.cropping[0][0],e.shape[2]-this.cropping[0][0]-this.cropping[0][1],3);return r.p(t,this.cropping[1][0],e.shape[3]-this.cropping[1][1]-this.cropping[1][0],4)}})}getConfig(){const e={cropping:this.cropping,dataFormat:this.dataFormat},t=super.getConfig();return Object.assign(e,t),e}}Cropping2D.className="Cropping2D",s.df.registerClass(Cropping2D);class UpSampling2D extends h.b{constructor(e){super(e),this.DEFAULT_SIZE=[2,2],this.inputSpec=[{ndim:4}],this.size=null==e.size?this.DEFAULT_SIZE:e.size,this.dataFormat=null==e.dataFormat?"channelsLast":e.dataFormat,Object(l.a)(this.dataFormat),this.interpolation=null==e.interpolation?"nearest":e.interpolation,Object(l.b)(this.interpolation)}computeOutputShape(e){if("channelsFirst"===this.dataFormat){const t=null==e[2]?null:this.size[0]*e[2],i=null==e[3]?null:this.size[1]*e[3];return[e[0],e[1],t,i]}{const t=null==e[1]?null:this.size[0]*e[1],i=null==e[2]?null:this.size[1]*e[2];return[e[0],t,i,e[3]]}}call(e,t){return s.Af(()=>{let t=Object(g.b)(e);const i=t.shape;if("channelsFirst"===this.dataFormat){t=s.Df(t,[0,2,3,1]);const e=this.size[0]*i[2],n=this.size[1]*i[3],a="nearest"===this.interpolation?s.oe.resizeNearestNeighbor(t,[e,n]):s.oe.resizeBilinear(t,[e,n]);return s.Df(a,[0,3,1,2])}{const e=this.size[0]*i[1],n=this.size[1]*i[2];return"nearest"===this.interpolation?s.oe.resizeNearestNeighbor(t,[e,n]):s.oe.resizeBilinear(t,[e,n])}})}getConfig(){const e={size:this.size,dataFormat:this.dataFormat,interpolation:this.interpolation},t=super.getConfig();return Object.assign(e,t),e}}UpSampling2D.className="UpSampling2D",s.df.registerClass(UpSampling2D)},205:function(e,t,i){"use strict";i.d(t,"b",(function(){return s})),i.d(t,"c",(function(){return n})),i.d(t,"d",(function(){return a})),i.d(t,"e",(function(){return r})),i.d(t,"a",(function(){return l}));
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
const s=["channelsFirst","channelsLast"],n=["nearest","bilinear"],a=["valid","same","causal"],r=["max","avg"],l=["sum","mul","concat","ave"]},207:function(e,t,i){"use strict";i.d(t,"d",(function(){return ReLU})),i.d(t,"b",(function(){return LeakyReLU})),i.d(t,"c",(function(){return PReLU})),i.d(t,"a",(function(){return ELU})),i.d(t,"f",(function(){return ThresholdedReLU})),i.d(t,"e",(function(){return Softmax}));var s=i(0),n=i(74),a=i(39),r=i(20),l=i(8),o=i(26),h=i(30),c=i(16);
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
class ReLU extends r.b{constructor(e){super(null==e?{}:e),this.supportsMasking=!0,null!=e&&(this.maxValue=e.maxValue)}call(e,t){e=Object(c.b)(e);let i=Object(s.Xe)(e);return null!=this.maxValue&&(i=Object(s.Jd)(i,0,this.maxValue)),i}computeOutputShape(e){return e}getConfig(){const e={maxValue:this.maxValue},t=super.getConfig();return Object.assign(e,t),e}}ReLU.className="ReLU",s.df.registerClass(ReLU);class LeakyReLU extends r.b{constructor(e){super(null==e?{}:e),this.DEFAULT_ALPHA=.3,null==e&&(e={}),this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const i=Object(c.b)(e);return Object(s.se)(i,this.alpha)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}LeakyReLU.className="LeakyReLU",s.df.registerClass(LeakyReLU);class PReLU extends r.b{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA_INITIALIZER="zeros",null==e&&(e={}),this.supportsMasking=!0,this.alphaInitializer=Object(o.q)(e.alphaInitializer||this.DEFAULT_ALPHA_INITIALIZER),this.alphaRegularizer=Object(h.b)(e.alphaRegularizer),this.alphaConstraint=Object(a.e)(e.alphaConstraint),null==e.sharedAxes)this.sharedAxes=null;else if(Array.isArray(e.sharedAxes))this.sharedAxes=e.sharedAxes;else{if("number"!=typeof e.sharedAxes)throw new l.e("Expected sharedAxes to be a number or an array of numbers, but got "+e.sharedAxes);this.sharedAxes=[e.sharedAxes]}}build(e){const t=(e=Object(c.a)(e)).slice(1);if(null!=this.sharedAxes)for(const e of this.sharedAxes)t[e-1]=1;this.alpha=this.addWeight("alpha",t,"float32",this.alphaInitializer,this.alphaRegularizer,!0,this.alphaConstraint);const i={};if(null!=this.sharedAxes)for(let t=1;t<e.length;++t)i[t]=e[t];this.inputSpec=[new r.a({ndim:e.length,axes:i})],this.built=!0}call(e,t){return e=Object(c.b)(e),Object(s.Re)(e,this.alpha.read())}getConfig(){const e={alphaInitializer:Object(o.r)(this.alphaInitializer),alphaRegularizer:Object(h.e)(this.alphaRegularizer),alphaConstraint:Object(a.f)(this.alphaConstraint),sharedAxes:this.sharedAxes},t=super.getConfig();return Object.assign(e,t),e}}PReLU.className="PReLU",s.df.registerClass(PReLU);class ELU extends r.b{constructor(e){if(super(null==e?{}:e),this.DEFAULT_ALPHA=1,null==e&&(e={}),null!=e.alpha&&e.alpha!==this.DEFAULT_ALPHA)throw new l.c(`Non-default alpha value (${e.alpha}) is not supported by the ELU layer yet.`);this.alpha=null==e.alpha?this.DEFAULT_ALPHA:e.alpha}call(e,t){const i=Object(c.b)(e);return Object(s.be)(i)}computeOutputShape(e){return e}getConfig(){const e={alpha:this.alpha},t=super.getConfig();return Object.assign(e,t),e}}ELU.className="ELU",s.df.registerClass(ELU);class ThresholdedReLU extends r.b{constructor(e){super(null==e?{}:e),this.DEFAULT_THETA=1,null==e&&(e={}),this.theta=null==e.theta?this.DEFAULT_THETA:e.theta}call(e,t){const i=Object(c.b)(e);return Object(s.Ie)(i,Object(s.Id)(Object(s.me)(i,this.theta),"float32"))}computeOutputShape(e){return e}getConfig(){const e={theta:this.theta},t=super.getConfig();return Object.assign(e,t),e}}ThresholdedReLU.className="ThresholdedReLU",s.df.registerClass(ThresholdedReLU);class Softmax extends r.b{constructor(e){super(null==e?{}:e),this.DEFAULT_AXIS=1,null==e&&(e={}),this.softmax=(new n.a).apply,this.axis=null==e.axis?this.DEFAULT_AXIS:e.axis}call(e,t){const i=Object(c.b)(e);return this.softmax(i,this.axis)}computeOutputShape(e){return e}getConfig(){const e={axis:this.axis},t=super.getConfig();return Object.assign(e,t),e}}Softmax.className="Softmax",s.df.registerClass(Softmax)},448:function(e,t,i){"use strict";i.d(t,"b",(function(){return s})),i.d(t,"a",(function(){return n}));
/**
 * @license
 * Copyright 2018 Google LLC
 *
 * Use of this source code is governed by an MIT-style
 * license that can be found in the LICENSE file or at
 * https://opensource.org/licenses/MIT.
 * =============================================================================
 */
const s=["fanIn","fanOut","fanAvg"],n=["normal","uniform","truncatedNormal"]}}]);